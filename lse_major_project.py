# -*- coding: utf-8 -*-
"""LSE_major_project.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1s6Nbm3D8qD6OqiLXdb7DOUHWinwf4CI4
"""

#this code is used for calculating the lip sync error , in this user needs to 
#upload original video file and wav2lip generated video files and lse will be calc.

import cv2
import numpy as np

def calculate_lip_sync_error(original_video_path, wav2lip_video_path):


    #  original video
    original_video = cv2.VideoCapture(original_video_path)
    # Wav2Lip-generated video
    wav2lip_video = cv2.VideoCapture(wav2lip_video_path)

    frame_count = 0
    total_error = 0

    while True:
        # Read frames from both videos
        ret1, original_frame = original_video.read()
        ret2, wav2lip_frame = wav2lip_video.read()

        # Check if frames are successfully read
        if not ret1 or not ret2:
            break

        # Preprocess frames if needed (resize, crop, extract lip region)

        # Converting  frames to grayscale both original and wav2lip
        original_gray = cv2.cvtColor(original_frame, cv2.COLOR_BGR2GRAY)
        wav2lip_gray = cv2.cvtColor(wav2lip_frame, cv2.COLOR_BGR2GRAY)

        # Calculate mean squared error (MSE) between the frames
        error = np.mean(np.square(original_gray - wav2lip_gray))

        # Accumulate total error
        total_error += error
        frame_count += 1

    # Calculate mean lip-sync error


    lip_sync_error = total_error / frame_count

    # Release video objects
    original_video.release()
    wav2lip_video.release()

    return lip_sync_error

# Paths to the original and Wav2Lip-generated videos
original_video_path = "/content/sample_data/usctimit_mri_f1_421_425_withaudio.avi"
wav2lip_video_path = "/content/sample_data/result_voice (6).mp4"

# Calculate lip-sync error between original and Wav2Lip videos
lip_sync_error = calculate_lip_sync_error(original_video_path, wav2lip_video_path)

print("Lip-sync error:", lip_sync_error)